{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VLFAri/Classificador-de-Imagens-de-Transporte/blob/main/Transportes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N609GVmiDBm"
      },
      "source": [
        "\n",
        "# Importando o DataSet do Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnqY2QYpOP1Q",
        "outputId": "d7d1d18c-14a4-4cfc-87f2-abce177f6a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #coloco o meu drive no sistema de arquivos do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AuiOqdlgkY1"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/DataSet' #Caminho do diretório onde estão as imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWqTmrgi2VY"
      },
      "source": [
        "# Importando biblioteca PyTorch e suas funcionalidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYzkRTUUjOZT"
      },
      "outputs": [],
      "source": [
        "#IMporta a biblioteca PyTorch para modelos de aprendizado de máquina e deep learning\n",
        "import torch\n",
        "\n",
        "#Importa do PyTorch a classe ImagemFolder para organização do dataset de imagens em pastas\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "#Importa do PyTorch o módulo transforms, usado para pré-processar imagens\n",
        "from torchvision import transforms\n",
        "\n",
        "#Classe DataLoader: cria um iterador sobre o dataset, dividindo-o em mini-batches, para depois ser utilizado no treinamento e validação\n",
        "#Classe Subset: separa imagens para treino e validação\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "#Importa a biblioteca NumPy, para cálculo de array e matrizes\n",
        "import numpy as np\n",
        "\n",
        "#Importa a função train_test_split do scikit-learn, para dividir dados em partes de treino e validação.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importa o módulo nn (Neural Networks) do PyTorch, utilizada para utilização das camadas de rede neural\n",
        "#Camadas utilizadas no módulo: nn.Linear e nn.Conv2D\n",
        "import torch.nn as nn\n",
        "\n",
        "#mporta o módulo functional, que contém as versões funcionais das operações das camadas, ex: ReLu\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Importa o módulo de otimizadores (nesse classificador o optimizador é o Adam)\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9TQSTGKjz1-"
      },
      "outputs": [],
      "source": [
        "#Esses são os valores médios e desvios padrão dos canais RGB do teu conjunto de imagens.\n",
        "#Utilizados para normalizar os dados\n",
        "media = [0.4201163053512573, 0.4290950298309326, 0.4315476417541504]\n",
        "desvio = [0.30978769063949585, 0.2988555133342743, 0.31542524695396423]\n",
        "\n",
        "#Cria uma pipeline de transformações a ser aplicada em cada imagem do dataset.\n",
        "#Resize: redimensiona todas as imagens para 224×224 pixels\n",
        "#ToTensor: converte a imagem de formato PIL (ou NumPy) para tensor do PyTorch\n",
        "#transforms.Normalize: normaliza cada canal RGB\n",
        "t = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),transforms.Normalize(media, desvio)\n",
        "])\n",
        "\n",
        "#Carrega o dataset de imagens localizado em path através da classe ImageFOlder utilizando o pipeline de transformação criado antes\n",
        "ds = ImageFolder(path, transform=t)\n",
        "\n",
        "#Extrai os rótulos numéricos (classes) de todas as imagens e converte para um array NumPy.\n",
        "#Facilita separação entre treinamento e validação\n",
        "tg = np.array(ds.targets)\n",
        "\n",
        "#Divide os índices do dataset em 70% treino e 30% validação.\n",
        "#stratify=tg → garante que a proporção de classes (ex: gatos/cachorros) seja mantida em ambas as partes.\n",
        "indice_treino, indice_validacao = train_test_split(np.arange(len(tg)),\n",
        "               test_size=0.3, stratify=tg, random_state=42)\n",
        "\n",
        "#Cria dois subconjuntos do dataset original (ds): um para treino e outro para validação\n",
        "treino = Subset(ds, indice_treino)\n",
        "validacao = Subset(ds, indice_validacao)\n",
        "\n",
        "#Cria os DataLoaders, que controlam o envio de dados à GPU/CPU durante o treinamento.\n",
        "#Batch de 64 imagens,\n",
        "#shuffle=True → embaralha os dados de treino a cada época (evita que o modelo aprenda padrões errados na ordem).\n",
        "#huffle=False → mantém a ordem na validação (não é necessário embaralhar).\n",
        "#num_workers=2 → usa 2 threads para carregar as imagens em paralelo (acelera o processo de leitura do disco).\n",
        "dl_treino = DataLoader(treino, batch_size = 64, shuffle=True, num_workers=2)\n",
        "dl_validacao = DataLoader(validacao, batch_size = 64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joP-Puo84z5W"
      },
      "outputs": [],
      "source": [
        "#Cria uma classe que define o modelo de rede neural, herdando de nn.Module — a classe base de todos os modelos no PyTorch.\n",
        "class ClassificarTipodeTransporte(nn.Module):\n",
        "#O método __init__ é o construtor da classe, onde são definidas todas as camadas da rede.\n",
        "  def __init__(self):\n",
        "    #A linha super(...) chama o construtor da classe nn.Module para inicializar a estrutura básica do modelo.\n",
        "    super(ClassificarTipodeTransporte, self).__init__()\n",
        "    #c1, c2 e c3 -> camadas convolucionais\n",
        "    #p1,p2 e p3 -> reduz a imagem pela metade em altura e largura, pegando o valor máximo em janelas 2×2.\n",
        "    #fc1,fc2,fc3 -> camadas fully-connected (redes neurais tradicionais)\n",
        "    self.c1 = nn.Conv2d(3,32,kernel_size=3,padding=1)\n",
        "    self.p1 = nn.MaxPool2d(2,2)\n",
        "    self.c2 = nn.Conv2d(32,64,kernel_size=3,padding=1)\n",
        "    self.p2 = nn.MaxPool2d(2,2)\n",
        "    self.c3 = nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.p3 = nn.MaxPool2d(2,2)\n",
        "    self.fc1 = nn.Linear(128*28*28,512)\n",
        "    self.fc2 = nn.Linear(512,128)\n",
        "    self.fc3 = nn.Linear(128,5)\n",
        "\n",
        "    #Adiciona dropout de 20%, uma técnica que desativa aleatoriamente 20% dos neurônios durante o treino\n",
        "    #Evita overfitting (modelo memoriza demais e começa a decorar ao invés de aprender)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  #Define como os dados passam pelas camadas da rede (a arquitetura em si).\n",
        "  def forward(self,x):\n",
        "    #ReLU (função de ativação que zera valores negativos) -> introduz não-linearidade\n",
        "    x = F.relu(self.c1(x))\n",
        "    x = self.p1(x)\n",
        "    x = F.relu(self.c2(x))\n",
        "    x = self.p2(x)\n",
        "    x = F.relu(self.c3(x))\n",
        "    x = self.p3(x)\n",
        "\n",
        "    #Achata (flatten) os dados: transforma o tensor 4D (batch, canais, altura, largura) em 2D (batch, total_de_valores_por_imagem)\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x #Retorna as previsões do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k9mCJOBpt5D"
      },
      "outputs": [],
      "source": [
        "#Cria uma instância da tua classe de rede neural ClassificarTipodeTransporte\n",
        "model = ClassificarTipodeTransporte()\n",
        "\n",
        "#Verifica se há uma GPU (CUDA) disponível: se tiver, a usa e usa o processador caso contrário\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Move todos os pesos e buffers do modelo para o dispositivo selecionado (GPU ou CPU).\n",
        "model.to(device)\n",
        "\n",
        "#Define a função de perda (loss function) usada para medir o erro do modelo.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Escolhe o otimizador Adam oara atualizar os pesos da rede com base nos gradientes calculados pela perda.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U9Ph2flZ0EW",
        "outputId": "63828286-120c-4d80-e78e-35de8b58a9bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidades de época que deseja treinar: 1\n",
            "Loss da 1ª época: 1.613814937216895\n"
          ]
        }
      ],
      "source": [
        "#Pede ao usuário o número de épocas de treinamento.\n",
        "#Cada época representa uma passagem completa por todo o conjunto de treino.\n",
        "print(\"Quantidades de época que deseja treinar:\",end=\" \")\n",
        "anos_treino = int(input())\n",
        "\n",
        "#Criação de um loop externo, que vai repetir o treinamento para cada época.\n",
        "for epoch in range(anos_treino):\n",
        "  model.train() #Coloca o modelo em modo de treinamento.\n",
        "  running_loss = 0.0 #Inicializa uma variável para acumular a perda (loss) de todos os lotes (batches) dessa época.\n",
        "  for inputs, labels in dl_treino: #Loop interno: percorre o DataLoader de treino, que fornece os dados em batches\n",
        "\n",
        "    #Move os dados do lote para o mesmo dispositivo do modelo (GPU ou CPU).\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad() #Zera os gradientes acumulados nas iterações anteriores (acumulados por padrão)\n",
        "    outputs = model(inputs) #Envia o lote de imagens pelo modelo (executa o método forward)\n",
        "    loss = criterion(outputs, labels) #Calcula a função de perda comparando as predições (outputs) com os rótulos verdadeiros (labels).\n",
        "    loss.backward() #Daz o backpropagation (calcula os gradientes em relação à perda)\n",
        "    optimizer.step() #O otimizador usa os gradientes calculados para atualizar os pesos da rede.\n",
        "\n",
        "    #Adiciona o valor da perda (convertido para número comum) à variável running_loss, acumulando o erro de todos os batches\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  #Ao final da época, exibe a perda média da época\n",
        "  print(f\"Loss da {epoch+1}ª época: {running_loss/len(dl_treino)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyJnuXr3qEFc",
        "outputId": "d4873654-e512-4604-9a72-ca5559d888cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 35.6%\n",
            "Loss: 1.523410141468048\n"
          ]
        }
      ],
      "source": [
        "model.eval() #Coloca o modelo em modo de validação.\n",
        "\n",
        "acerto = 0\n",
        "total = 0\n",
        "loss_total = 0\n",
        "\n",
        "with torch.no_grad(): #Desativa o cálculo de gradientes\n",
        "\n",
        "  #Cada lote (batch) de imagens e rótulos é passado pela rede.\n",
        "  #outputs são as probabilidades ou pontuações de cada classe.\n",
        "  for inputs, label in dl_validacao:\n",
        "    inputs = inputs.to(device)\n",
        "    label = label.to(device)\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    #A função de custo (CrossEntropyLoss) mede o quanto o modelo está errando as previsões.\n",
        "    #loss_total acumula o erro de todos os lotes.\n",
        "    loss = criterion(outputs, label)\n",
        "    loss_total += loss.item()\n",
        "\n",
        "    #torch.max(outputs, 1) pega o índice da classe com maior pontuação (a previsão final)\n",
        "    #Compara com os rótulos reais (label) e soma quantos estão corretos.\n",
        "    #total é o total de amostras, e acerto é o total de acertos.\n",
        "    _,predicao = torch.max(outputs, 1)\n",
        "    total += label.size(0)\n",
        "    acerto += (predicao == label).sum().item()\n",
        "\n",
        "  loss_final = loss_total / len(dl_validacao) #erro médio por lote na validação.\n",
        "  acuracia = (acerto/total)*100 #porcentagem de acertos do modelo.\n",
        "  print(f\"Acurácia: {acuracia}%\")\n",
        "  print(f\"Loss: {loss_final}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbQ937lVufjBj2eaMSVzsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}